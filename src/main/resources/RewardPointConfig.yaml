jobName: RewardPoint

spark:
  spark.speculation: true
  spark.speculation.interval: 600s
  spark.master: local[4]
  spark.driver.memory: 256M
  spark.executor.memory: 1G
  #spark.ui.enabled: false

source:
  type: file                  # We may support in future other types like http, ftp, hdfs or kafka
  codec:                      # We may support other codecs in future like json, tsv or any custom codec
    type: csv
    schema:                   # Spark can infer schema automatically but it will require an extra pass through the data, hence better to provide schema ourselves
      - ["Transaction ID", String]
      - ["Customer ID", String]
      - ["Customer Name", String]
      - ["Bank Name", String]
      - ["Transaction Amount (EUR)", Double]
      - ["Merchant Name", String]
      - ["Merchant Type", String]
      - ["Transaction Country", String]
      - ["Transaction Type", String]
  paths:
    - /tmp/transactions.csv

rules: RewardPoint.drl        # Business rules to calculate reward points

sink:
  type: file                  # We may support in future other types like http, ftp, hdfs or kafka
  codec:                      # We may support other codecs in future like json, tsv or any custom codec
    type: json
  paths:
    - /tmp/rewards
